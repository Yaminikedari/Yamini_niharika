{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17656729-1e02-44d4-b18c-97380a512312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Step 1: Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"LoanPredictionMLP\").getOrCreate()\n",
    "\n",
    "# Step 2: Load Dataset\n",
    "data = spark.read.csv(\"C:/Users/yamin/OneDrive/Desktop/BD/CreditRisk (1).csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Step 3: Data Preprocessing\n",
    "# Replace nulls in numerical columns with median or mean values\n",
    "numerical_columns = [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\", \"Credit_History\"]\n",
    "for col_name in numerical_columns:\n",
    "    median_value = data.approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "    data = data.fillna({col_name: median_value})\n",
    "\n",
    "# Replace nulls in categorical columns with \"Unknown\"\n",
    "categorical_columns = [\"Gender\", \"Married\", \"Dependents\", \"Education\", \"Self_Employed\", \"Property_Area\"]\n",
    "for col_name in categorical_columns:\n",
    "    data = data.withColumn(col_name, when(col(col_name).isNull(), \"Unknown\").otherwise(col(col_name)))\n",
    "\n",
    "# Encode categorical columns using StringIndexer\n",
    "for col_name in categorical_columns:\n",
    "    indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\")\n",
    "    data = indexer.fit(data).transform(data)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(*categorical_columns)\n",
    "\n",
    "# Convert target variable to numerical\n",
    "label_indexer = StringIndexer(inputCol=\"Loan_Status\", outputCol=\"label\")\n",
    "data = label_indexer.fit(data).transform(data)\n",
    "data = data.drop(\"Loan_Status\")\n",
    "\n",
    "# Step 4: Assemble Features\n",
    "feature_cols = [col for col in data.columns if col != \"label\" and col != \"Loan_ID\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "# Step 5: Train-Test Split\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Step 6: Define the Model\n",
    "layers = [len(feature_cols), 10, 5, 2]  # Adjust the layers as per your requirements\n",
    "mlp = MultilayerPerceptronClassifier(layers=layers, featuresCol=\"features\", labelCol=\"label\", maxIter=100)\n",
    "\n",
    "# Step 7: Train the Model\n",
    "mlp_model = mlp.fit(train_data)\n",
    "\n",
    "# Step 8: Make Predictions\n",
    "predictions = mlp_model.transform(test_data)\n",
    "\n",
    "# Step 9: Evaluate the Model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0fcd965-de3f-4614-bcae-fee4185b79fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.69\n",
      "Test Precision: 0.48\n",
      "Test Recall: 0.69\n",
      "Test F1-Score: 0.57\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# Step 1: Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"LoanPredictionMLP\").getOrCreate()\n",
    "\n",
    "# Step 2: Load Dataset\n",
    "data = spark.read.csv(\"C:/Users/yamin/OneDrive/Desktop/BD/CreditRisk (1).csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Step 3: Data Preprocessing\n",
    "# Replace nulls in numerical columns with median values\n",
    "numerical_columns = [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\", \"Credit_History\"]\n",
    "for col_name in numerical_columns:\n",
    "    median_value = data.approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "    data = data.fillna({col_name: median_value})\n",
    "\n",
    "# Replace nulls in categorical columns with \"Unknown\"\n",
    "categorical_columns = [\"Gender\", \"Married\", \"Dependents\", \"Education\", \"Self_Employed\", \"Property_Area\"]\n",
    "for col_name in categorical_columns:\n",
    "    data = data.withColumn(col_name, when(col(col_name).isNull(), \"Unknown\").otherwise(col(col_name)))\n",
    "\n",
    "# Encode categorical columns using StringIndexer\n",
    "for col_name in categorical_columns:\n",
    "    indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\")\n",
    "    data = indexer.fit(data).transform(data)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(*categorical_columns)\n",
    "\n",
    "# Convert target variable to numerical\n",
    "label_indexer = StringIndexer(inputCol=\"Loan_Status\", outputCol=\"label\")\n",
    "data = label_indexer.fit(data).transform(data)\n",
    "data = data.drop(\"Loan_Status\")\n",
    "\n",
    "# Step 4: Assemble Features\n",
    "feature_cols = [col for col in data.columns if col != \"label\" and col != \"Loan_ID\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "# Step 5: Train-Test Split\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Step 6: Define the Model\n",
    "layers = [len(feature_cols), 10, 5, 2]  # Adjust the layers as per your requirements\n",
    "mlp = MultilayerPerceptronClassifier(layers=layers, featuresCol=\"features\", labelCol=\"label\", maxIter=100)\n",
    "\n",
    "# Step 7: Train the Model\n",
    "mlp_model = mlp.fit(train_data)\n",
    "\n",
    "# Step 8: Make Predictions\n",
    "predictions = mlp_model.transform(test_data)\n",
    "\n",
    "# Step 9: Evaluate the Model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1_score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Test Precision: {precision:.2f}\")\n",
    "print(f\"Test Recall: {recall:.2f}\")\n",
    "print(f\"Test F1-Score: {f1_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2743ffd-000c-4077-9683-2f6b004b13f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+----------------+--------------+--------------------+----------+\n",
      "|ApplicantIncome|CoapplicantIncome|Loan_Amount_Term|Credit_History|       rawPrediction|prediction|\n",
      "+---------------+-----------------+----------------+--------------+--------------------+----------+\n",
      "|           3000|              0.0|             360|             1|[0.25383782538227...|       0.0|\n",
      "|           2333|           1516.0|             360|             1|[0.25383782538227...|       0.0|\n",
      "|           5720|              0.0|             360|             1|[0.25383782538227...|       0.0|\n",
      "|           2500|           1840.0|             360|             1|[0.25383782538227...|       0.0|\n",
      "|           3596|              0.0|             240|             1|[0.25383782538227...|       0.0|\n",
      "|           2600|           3500.0|             360|             1|[0.25383782538227...|       0.0|\n",
      "|           3717|           2925.0|             360|             1|[0.25383782538227...|       0.0|\n",
      "|           2400|           2400.0|             360|             1|[0.25383782538227...|       0.0|\n",
      "|           3167|              0.0|             360|             1|[0.25383782538227...|       0.0|\n",
      "|           4666|              0.0|             360|             1|[0.25383782538227...|       0.0|\n",
      "+---------------+-----------------+----------------+--------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Step 1: Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"LoanPredictionMLP\").getOrCreate()\n",
    "\n",
    "# Step 2: Load Dataset\n",
    "data = spark.read.csv(\"C:/Users/yamin/OneDrive/Desktop/BD/CreditRisk (1).csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Step 3: Data Preprocessing\n",
    "# Replace nulls in numerical columns with median values\n",
    "numerical_columns = [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\", \"Credit_History\"]\n",
    "for col_name in numerical_columns:\n",
    "    median_value = data.approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "    data = data.fillna({col_name: median_value})\n",
    "\n",
    "# Replace nulls in categorical columns with \"Unknown\"\n",
    "categorical_columns = [\"Gender\", \"Married\", \"Dependents\", \"Education\", \"Self_Employed\", \"Property_Area\"]\n",
    "for col_name in categorical_columns:\n",
    "    data = data.withColumn(col_name, when(col(col_name).isNull(), \"Unknown\").otherwise(col(col_name)))\n",
    "\n",
    "# Encode categorical columns using StringIndexer\n",
    "for col_name in categorical_columns:\n",
    "    indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\")\n",
    "    data = indexer.fit(data).transform(data)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(*categorical_columns)\n",
    "\n",
    "# Convert target variable to numerical\n",
    "label_indexer = StringIndexer(inputCol=\"Loan_Status\", outputCol=\"label\")\n",
    "data = label_indexer.fit(data).transform(data)\n",
    "data = data.drop(\"Loan_Status\")\n",
    "\n",
    "# Step 4: Assemble Features\n",
    "feature_cols = [col for col in data.columns if col != \"label\" and col != \"Loan_ID\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "# Step 5: Train-Test Split\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Step 6: Define the Model\n",
    "layers = [len(feature_cols), 10, 5, 2]  # Adjust the layers as per your requirements\n",
    "mlp = MultilayerPerceptronClassifier(layers=layers, featuresCol=\"features\", labelCol=\"label\", maxIter=100)\n",
    "\n",
    "# Step 7: Train the Model\n",
    "mlp_model = mlp.fit(train_data)\n",
    "\n",
    "# Step 8: Make Predictions\n",
    "predictions = mlp_model.transform(test_data)\n",
    "\n",
    "# Step 9: Display required columns from the predictions\n",
    "predictions.select(\n",
    "    'ApplicantIncome', \n",
    "    'CoapplicantIncome', \n",
    "    'Loan_Amount_Term', \n",
    "    'Credit_History', \n",
    "    'rawPrediction', \n",
    "    'prediction'\n",
    ").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dee5206-d149-4444-b6e2-e359726a5b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.72\n",
      "Precision: 0.80\n",
      "Recall: 0.72\n",
      "+---------------+-----------------+----------------+--------------+--------------------+----------+\n",
      "|ApplicantIncome|CoapplicantIncome|Loan_Amount_Term|Credit_History|       rawPrediction|prediction|\n",
      "+---------------+-----------------+----------------+--------------+--------------------+----------+\n",
      "|           3000|              0.0|             360|             1|[-0.0996178605546...|       0.0|\n",
      "|           2333|           1516.0|             360|             1|[0.08510741834182...|       0.0|\n",
      "|           5720|              0.0|             360|             1|[-0.0709797313010...|       0.0|\n",
      "|           2500|           1840.0|             360|             1|[0.15254882478354...|       0.0|\n",
      "|           3596|              0.0|             240|             1|[-0.0857244793366...|       0.0|\n",
      "|           2600|           3500.0|             360|             1|[-0.0537997316019...|       0.0|\n",
      "|           3717|           2925.0|             360|             1|[0.16823759357055...|       0.0|\n",
      "|           2400|           2400.0|             360|             1|[0.23592923405023...|       0.0|\n",
      "|           3167|              0.0|             360|             1|[-0.0996178363081...|       0.0|\n",
      "|           4666|              0.0|             360|             1|[-0.0886945073260...|       0.0|\n",
      "+---------------+-----------------+----------------+--------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Step 1: Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"LoanPredictionMLPImproved\").getOrCreate()\n",
    "\n",
    "# Step 2: Load Dataset\n",
    "data = spark.read.csv(\"C:/Users/yamin/OneDrive/Desktop/BD/CreditRisk (1).csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Step 3: Data Preprocessing (same as before)\n",
    "# Replace nulls in numerical columns with median values\n",
    "numerical_columns = [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\", \"Credit_History\"]\n",
    "for col_name in numerical_columns:\n",
    "    median_value = data.approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "    data = data.fillna({col_name: median_value})\n",
    "\n",
    "# Replace nulls in categorical columns with \"Unknown\"\n",
    "categorical_columns = [\"Gender\", \"Married\", \"Dependents\", \"Education\", \"Self_Employed\", \"Property_Area\"]\n",
    "for col_name in categorical_columns:\n",
    "    data = data.withColumn(col_name, when(col(col_name).isNull(), \"Unknown\").otherwise(col(col_name)))\n",
    "\n",
    "# Encode categorical columns using StringIndexer\n",
    "for col_name in categorical_columns:\n",
    "    indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\")\n",
    "    data = indexer.fit(data).transform(data)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(*categorical_columns)\n",
    "\n",
    "# Convert target variable to numerical\n",
    "label_indexer = StringIndexer(inputCol=\"Loan_Status\", outputCol=\"label\")\n",
    "data = label_indexer.fit(data).transform(data)\n",
    "data = data.drop(\"Loan_Status\")\n",
    "\n",
    "# Step 4: Assemble Features\n",
    "feature_cols = [col for col in data.columns if col != \"label\" and col != \"Loan_ID\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "# Step 5: Train-Test Split\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Step 6: Define the Model (with larger architecture)\n",
    "layers = [len(feature_cols), 128, 64, 32, 2]  # Adding more neurons and layers for complexity\n",
    "mlp = MultilayerPerceptronClassifier(layers=layers, featuresCol=\"features\", labelCol=\"label\", maxIter=100)\n",
    "\n",
    "# Step 7: Hyperparameter Tuning with Cross-Validation\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(mlp.maxIter, [100, 200]) \\\n",
    "    .addGrid(mlp.layers, [[len(feature_cols), 128, 64, 32, 2], [len(feature_cols), 256, 128, 64, 2]]) \\\n",
    "    .addGrid(mlp.blockSize, [128, 256]) \\\n",
    "    .build()\n",
    "\n",
    "# Evaluator to check accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# CrossValidator for hyperparameter tuning\n",
    "cv = CrossValidator(estimator=mlp, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# Step 8: Train the Model\n",
    "cv_model = cv.fit(train_data)\n",
    "\n",
    "# Step 9: Make Predictions\n",
    "predictions = cv_model.transform(test_data)\n",
    "\n",
    "# Step 10: Evaluate the Model\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Additional evaluation metrics (Precision, Recall)\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "precision = precision_evaluator.evaluate(predictions)\n",
    "recall = recall_evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# Step 11: Display required columns from the predictions\n",
    "predictions.select(\n",
    "    'ApplicantIncome', \n",
    "    'CoapplicantIncome', \n",
    "    'Loan_Amount_Term', \n",
    "    'Credit_History', \n",
    "    'rawPrediction', \n",
    "    'prediction'\n",
    ").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e04091-672f-492e-a116-a03996db1779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
